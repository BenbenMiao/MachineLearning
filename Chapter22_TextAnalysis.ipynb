{
  "cells": [
    {
      "metadata": {
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "code",
      "source": "from sklearn.datasets import load_files\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom matplotlib import pyplot as plt\n\n# 1) 导入数据\ncategories = ['alt.atheism',\n              'rec.sport.hockey',\n              'comp.graphics',\n              'sci.crypt',\n              'comp.os.ms-windows.misc',\n              'sci.electronics',\n              'comp.sys.ibm.pc.hardware',\n              'sci.med',\n              'comp.sys.mac.hardware',\n              'sci.space',\n              'comp.windows.x',\n              'soc.religion.christian',\n              'misc.forsale',\n              'talk.politics.guns',\n              'rec.autos' \n              'talk.politics.mideast',\n              'rec.motorcycles',\n              'talk.politics.misc',\n              'rec.sport.baseball',\n              'talk.religion.misc']\n# 导入训练数据\ntrain_path = '20news-bydate-train'\ndataset_train = load_files(container_path=train_path, categories=categories)\n# 导入评估数据\ntest_path = '20news-bydate-test'\ndataset_test = load_files(container_path=test_path, categories=categories)\n\n# 2）数据准备与理解\n\n# 计算词频\ncount_vect = CountVectorizer(stop_words='english', decode_error='ignore')\nX_train_counts = count_vect.fit_transform(dataset_train.data)\n# 查看数据维度\nprint(X_train_counts.shape)\n\n# 计算TF-IDF\ntf_transformer = TfidfVectorizer(stop_words='english', decode_error='ignore')\nX_train_counts_tf = tf_transformer.fit_transform(dataset_train.data)\n# 查看数据维度\nprint(X_train_counts_tf.shape)\n\n\n# 设置评估算法的基准\nnum_folds = 10\nseed = 7\nscoring = 'accuracy'\n\n\n# 3）评估算法\n# 生成算法模型\nmodels = {}\nmodels['LR'] = LogisticRegression()\nmodels['SVM'] = SVC()\nmodels['CART'] = DecisionTreeClassifier()\nmodels['MNB'] = MultinomialNB()\nmodels['KNN'] = KNeighborsClassifier()\n\n# 比较算法\nresults = []\nfor key in models:\n    kfold = KFold(n_splits=num_folds, random_state=seed)\n    cv_results = cross_val_score(models[key], X_train_counts_tf, dataset_train.target, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    print('%s : %f (%f)' % (key, cv_results.mean(), cv_results.std()))\n\n# 箱线图比较算法\nfig = plt.figure()\nfig.suptitle('Algorithm Comparision')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(models.keys())\nplt.show()\n\n# 4）算法调参\n# 调参LR\nparam_grid = {}\nparam_grid['C'] = [0.1, 5, 13, 15]\nmodel = LogisticRegression()\nkfold = KFold(n_splits=num_folds, random_state=seed)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\ngrid_result = grid.fit(X=X_train_counts_tf, y=dataset_train.target)\nprint('最优 : %s 使用 %s' % (grid_result.best_score_, grid_result.best_params_))\n\n# 调参MNB\nparam_grid = {}\nparam_grid['alpha'] = [0.001, 0.01, 0.1, 1.5]\nmodel = MultinomialNB()\nkfold = KFold(n_splits=num_folds, random_state=seed)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\ngrid_result = grid.fit(X=X_train_counts_tf, y=dataset_train.target)\nprint('最优 : %s 使用 %s' % (grid_result.best_score_, grid_result.best_params_))\n\n# 5）集成算法\nensembles = {}\nensembles['RF'] = RandomForestClassifier()\nensembles['AB'] = AdaBoostClassifier()\n# 比较集成算法\nresults = []\nfor key in ensembles:\n    kfold = KFold(n_splits=num_folds, random_state=seed)\n    cv_results = cross_val_score(ensembles[key], X_train_counts_tf, dataset_train.target, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    print('%s : %f (%f)' % (key, cv_results.mean(), cv_results.std()))\n\n# 箱线图比较算法\nfig = plt.figure()\nfig.suptitle('Algorithm Comparision')\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(ensembles.keys())\nplt.show()\n\n# 调参RF\nparam_grid = {}\nparam_grid['n_estimators'] = [10, 100, 150, 200]\nmodel = RandomForestClassifier()\nkfold = KFold(n_splits=num_folds, random_state=seed)\ngrid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)\ngrid_result = grid.fit(X=X_train_counts_tf, y=dataset_train.target)\nprint('最优 : %s 使用 %s' % (grid_result.best_score_, grid_result.best_params_))\n\n# 6）生成模型\nmodel = LogisticRegression(C=13)\nmodel.fit(X_train_counts_tf, dataset_train.target)\nX_test_counts = tf_transformer.transform(dataset_test.data)\npredictions = model.predict(X_test_counts)\nprint(accuracy_score(dataset_test.target, predictions))\nprint(classification_report(dataset_test.target, predictions))",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}